- work文件存储了我从最开始慢慢学习LangChain的过程，从0开始做一个小的个人项目
  - W1文件夹  主要是学习一些基础的交互
    - T1 基础的爬虫脚本，使用 requests 库请求一个公开API，并打印返回的状态码和原始文本内容
      - HTTP请求的基本原理  
      - GET请求是如何工作的
      - request都有什么方法
      - 状态码都有哪些
    - T2 对爬取到的内容的分析
      - 爬取到的内容是什么格式
      - 要转换为什么格式常用  如何转换
    - T4 不使用库 手动调用大模型  构建HTTP请求
      - 构建请求需要的东西都有什么
      - 如何构建请求头  请求体
    - T5 使用LangChain进行调用大模型
      - 需要调用的库是什么
      - 如何配置大模型接口
      - 两种输出的方式都是什么  什么方法实现的
      - "".join()  是干什么的  什么效果
    - T6 一个完整的爬虫项目  
      - 发送请求必须有的是什么  如何模仿浏览器
      - get方法如何设置超时
      - 使用什么解析HTML   解析的效果是什么
      - 如何查找标签  获取标签的内容
      - 如何去除重复的内容
      - 循环中枚举函数的使用用法
  - W2文件夹  逐步实现一个小的RAG系统的过程
    - T1 加载PDF输出内容
      - 通过什么对象  什么方法 加载PDF
      - 如何获取当前的文件路径   如何智能拼接路径
      - 加载后是什么数据类型  里面是什么内容
      - 如何查看PDF的文本内容
      - 切片是什么
    - T2 把加载的PDF文件分割成小的文本块
      - 用什么对象  什么方法  进行分割
      - 分割器实例的参数都有什么
      - 分割完是什么数据类型  里面是什么内容
      - 如何查看分割后的文本内容
      - 如何查看分割后的文本块的数量
    - T3 把分割后的内容转换为向量并存储在向量数据库  并根据内容进行检索
      - 遥控器是什么 翻译官是什么
      - 遥控器 翻译官的参数有什么
      - 什么方法把文档添加到数据库  自动向量化
      - 如何查询数据库中当前存储的条目总数
      - 怎么相似搜索查找
    - T4 创建一个完整的RAG链  输入问题->检索->将问题和上下文组合成Prompt->发送给LLM->获得答案
      - qa链的参数
      - 如何将向量数据库转换为一个“检索器”组件
      - qa链如何调用
      - 调用qa链的结果是什么数据类型  
    - T5 封装RAG链
      - 
- 
- 
    

          T2 从一个公开API获取数据，并解析成Python字典，然后提取出我们关心的信息
          T3 从一个公开API获取数据，并解析成Python字典，然后提取出我们关心的信息
          T4 通过查阅官方文档，我们了解了如何构造一个符合API要求的请求体
          T5 使用 LangChain 库来调用大模型API
      W2文件夹  主要是学习一些RAG系统
          T1 从PDF中提取文本
          T2 将提取的文本进行分段
          T3 将分段的文本存储到向量数据库中
          T4 创建一个完整的RAG链
          T5 将RAG链封装成一个函数或类
      W3文件夹  主要是学习一些LangChain的进阶用法